@config_enumerate
def model(data, K):
    N, D, _ = data.shape
    # prior distributions
    weights = pyro.sample("weights", dist.Dirichlet(0.5 * torch.ones(K)))
    #height = pyro.sample("height", dist.HalfNormal(500.))
    #background = pyro.sample("background", dist.HalfNormal(1000.))
    #width = pyro.sample("width", dist.Gamma(1., 0.1)) # dist.HalfNormal(100.)
    # class templates
    #locs = torch.zeros((K,D,D))
    #locs[0,:,:] = classB(background)
    #locs[1,:,:] = classA(height, width, background)
    
    beta = 0.1
    lamda_beta = torch.zeros((K,D,D))
    lamda_beta[0,:,:] = torch.ones(D, D) * beta
    lamda_beta[1,:,:] = torch.ones(D, D) * beta
    
    lamda_alpha = torch.zeros((K,D,D))
    lamda_alpha[0,:,:] = beta * classB(1.)
    lamda_alpha[1,:,:] = beta * classA(1., 0.1, 1.)
    lamda = pyro.sample("lamda", dist.Gamma(lamda_alpha, lamda_beta).to_event(3)) # prior
    
    #locs_loc = torch.zeros((K,D,D))
    #locs_loc[0,:,:] = classB(500.)
    #locs_loc[1,:,:] = classA(100., 0.5, 500.)
    #locs = pyro.sample("locs", dist.Normal(locs_loc, 500.).to_event(3))
    #sigma = pyro.sample("sigma", dist.Gamma(1, 0.001))
    with pyro.plate("sample_size", N):
    #with pyro.plate("sample_size", size=N, subsample_size=1000, device=device) as ind:
        # hidden states
        z = pyro.sample("z", dist.Categorical(weights))
        # likelihood / conditioning on data
        #pyro.sample("obs", dist.Normal(locs[z,:,:], sigma).to_event(2), obs=data[ind])
        #pyro.sample("obs", dist.Normal(locs[z,:,:], sigma).to_event(2), obs=data)
        pyro.sample("obs", dist.Poisson(lamda[z,:,:]).to_event(2), obs=data)
        #pyro.sample("obs", dist.Normal(locs[z,:,:], sigma).to_event(2), obs=data)
        
def guide(data, K):
    N, D, _ = data.shape
    # posterior approximations
    weights_conc = pyro.param("weights_conc", torch.ones(K)*0.5, constraint=constraints.positive)
    weights = pyro.sample("weights", dist.Dirichlet(weights_conc))
    
    #height_loc = pyro.param("height_loc", torch.tensor(100.))
    #height_scale = pyro.param("height_scale", torch.tensor(20.), constraint=constraints.positive)
    #height = pyro.sample("height", dist.Normal(height_loc, height_scale)) # true distribution
    
    #background_loc = pyro.param("background_loc", torch.tensor(360.))
    #background_scale = pyro.param("background_scale", torch.tensor(50.), constraint=constraints.positive)
    #background = pyro.sample('background', dist.Normal(background_loc, background_scale))
    
    #width_alpha = pyro.param("width_alpha", torch.tensor(10.), constraint=constraints.positive)
    #width_beta = pyro.param("width_beta", torch.tensor(20.), constraint=constraints.positive)
    #width = pyro.sample("width", dist.Gamma(width_alpha, width_beta))
    
    height = pyro.param("height", torch.tensor(100.), constraint=constraints.positive)
    width = pyro.param("width", torch.tensor(0.5), constraint=constraints.positive)
    background = pyro.param("background", torch.tensor(500.), constraint=constraints.positive)
    
    #beta = pyro.param("beta", torch.tensor(1.), constraint=constraints.positive)    
    #lamda_beta = torch.zeros((K,D,D))
    lamda_beta = pyro.param("beta", torch.ones(K,D,D), constraint=constraints.positive)
    #lamda_beta[0,:,:] = torch.ones(D, D)
    #lamda_beta[1,:,:] = torch.ones(D, D)
    
    lamda_alpha = torch.zeros((K,D,D))
    lamda_alpha[0,:,:] = lamda_beta[0,:,:] * classB(background)
    lamda_alpha[1,:,:] = lamda_beta[0,:,:] * classA(height, width, background)
    lamda = pyro.sample("lamda", dist.Gamma(lamda_alpha, lamda_beta).to_event(3)) # posterior
    
    #locs_scale = pyro.param("locs_scale", torch.tensor(200.))
    
    #locs_loc = torch.zeros((K,D,D))
    #locs_loc[0,:,:] = classB(background)
    #locs_loc[1,:,:] = classA(height, width, background)
    #locs = pyro.sample("locs", dist.Normal(locs_loc, locs_scale).to_event(3))
    
    #sigma_alpha = pyro.param("sigma_alpha", torch.tensor(20.), constraint=constraints.positive)
    #sigma_beta = pyro.param("sigma_beta", torch.tensor(4.), constraint=constraints.positive)
    #sigma = pyro.sample("sigma", dist.Gamma(sigma_alpha, sigma_beta))
    
    
@config_enumerate
def model(data, K):
    N, D, _ = data.shape
    # prior distributions
    weights = pyro.sample("weights", dist.Dirichlet(0.5 * torch.ones(K)))
    
    height = pyro.sample("height", dist.HalfNormal(500.))
    background = pyro.sample("background", dist.HalfNormal(1000.))
    width = pyro.sample("width", dist.Gamma(1., 0.1)) # dist.HalfNormal(100.)
    # class templates
    locs = torch.zeros((K,D,D))
    locs[0,:,:] = classB(background, D)
    locs[1,:,:] = classA(height, width, background, D)
    
    beta = pyro.param("beta", torch.tensor(50.), constraint=constraints.positive)
    #lamda_beta = torch.ones((K,D,D)) * beta
    #lamda_alpha = torch.zeros((K,D,D))
    #lamda_alpha[0,:,:] = beta * classB(1., D)
    #lamda_alpha[1,:,:] = beta * classA(1., 0.5, 1., D)
    #lamda_alpha = torch.stack((beta * classB(1., D), beta * classA(1., 0.5, 1., D)))
    #lamda = pyro.sample("lamda", dist.Gamma(lamda_alpha, lamda_beta).to_event(3)) # prior

    with pyro.plate("sample_size", N):
        # hidden states
        z = pyro.sample("z", dist.Categorical(weights))
        # likelihood / conditioning on data
        #pyro.sample("obs", dist.Poisson(locs[z,:,:]).to_event(2), obs=data)
        pyro.sample("obs", dist.Gamma(locs[z,:,:]*beta, beta).to_event(2), obs=data)

# 06/18/2019
def guide(data, K):
    N, D, _ = data.shape
    # posterior approximations
    weights_conc = pyro.param("weights_conc", torch.ones(K), constraint=constraints.positive)
    #print(weights_conc)
    weights = pyro.sample("weights", dist.Dirichlet(weights_conc))
    
    #height = pyro.param("height", torch.tensor(200.), constraint=constraints.positive)
    #width = pyro.param("width", torch.tensor(1.), constraint=constraints.positive)
    #background = pyro.param("background", torch.tensor(400.), constraint=constraints.positive)
    
    beta = pyro.param("beta", torch.tensor(2.), constraint=constraints.positive)    
    #lamda_beta = torch.ones((K,D,D)) * beta
    #lamda_beta[0,:,:] *= weights[0]
    #lamda_beta[1,:,:] *= weights[1]
    #lamda_alpha = torch.stack((beta * classB(background, D), beta * classA(height, width, background, D)))
    #lamda_alpha[0,:,:] *= weights[0]
    #lamda_alpha[1,:,:] *= weights[1]
    #lamda = pyro.sample("lamda", dist.Gamma(lamda_alpha, lamda_beta).to_event(3)) # posterior
    
    height_loc = pyro.param("height_loc", torch.tensor(100.), constraint=constraints.positive)
    height_scale = pyro.param("height_scale", torch.tensor(20.), constraint=constraints.positive)
    height = pyro.sample("height", dist.Normal(height_loc, height_scale)) # true distribution
    
    background_loc = pyro.param("background_loc", torch.tensor(360.), constraint=constraints.positive)
    background_scale = pyro.param("background_scale", torch.tensor(50.), constraint=constraints.positive)
    background = pyro.sample('background', dist.Normal(background_loc, background_scale))
    
    width_alpha = pyro.param("width_alpha", torch.tensor(10.), constraint=constraints.positive)
    width_beta = pyro.param("width_beta", torch.tensor(20.), constraint=constraints.positive)
    width = pyro.sample("width", dist.Gamma(width_alpha, width_beta))
    
# 07/07/2019
aoi_widget = widgets.Dropdown(options=smd["info"].keys())
frame_widget = widgets.Dropdown(options=[(j,i) for i,j in enumerate(frame_list[0])])

def update_framelist(change):
    frame_widget.options = [(j,i) for i,j in enumerate(smd["info"][change["new"]].index)]
aoi_widget.observe(update_framelist, "value")

interact(view_aoi, aoi=aoi_widget, frame=frame_widget, smd=fixed(smd))

def view_aoi(aoi, frame, data):
    fig = plt.figure(figsize=(15,3))
    for i in range(20):
        ax = fig.add_subplot(2,10,i+1)
        plt.title("f {:d}".format(smd["info"][aoi].index[frame+i]))
        vmin = np.percentile(smd["data"][aoi].cpu(), 5)
        vmax = np.percentile(smd["data"][aoi].cpu(), 99)
        plt.imshow(smd["data"][aoi][frame+i].cpu(), cmap="gray", vmin=vmin, vmax=vmax)
        plt.gca().axes.xaxis.set_ticklabels([])
        plt.gca().axes.yaxis.set_ticklabels([])
    plt.tight_layout()
    plt.show()
    
# 07/07/2019
# deprecated; use tensorboard
#interact(view_history, filename=[file for file in os.listdir(os.path.join(path, "checkpoints")) if file.endswith(".pkl")],
#        path=fixed(path))
def view_history(filename, path):
    history = load_obj(os.path.join(path, "checkpoints", filename))
    rows = math.ceil(len(history)/3)
    plt.figure(figsize=(15,4*rows))
    i = 1
    for p in history.keys():
        if isinstance(history[p], list):
            if isinstance(history[p][0], float):
                plt.subplot(rows,3,i)
                plt.plot(history[p])
                plt.xlabel("iters")
                plt.title(p)
                i += 1
            elif isinstance(history[p][0], list):
                plt.subplot(rows,3,i)
                for j in range(min(len(history[p][0]),5)):
                    plt.plot([w[j] for w in history[p]])
                plt.xlabel("iters")
                plt.title(p)
                i += 1

    plt.tight_layout()
    plt.show()
    
# 07/07/2019
# deprecated; use tensorboard ;)
def intensity_hist_by_class(data, sample_data, K):

    fig = plt.figure(figsize=(12,4), dpi=100)
    for k in range(K):
        plt.subplot(1,3,k+1)
        plt.hist(data[torch.tensor((data.info["predictions"] == k).values)].reshape(-1).cpu(), bins=50, alpha=0.3)
        plt.hist(sample_data[torch.tensor((data.info["predictions"] == k).values)].reshape(-1), bins=50, alpha=0.3)
        plt.title("state {}".format(k))
        plt.ylabel("counts")
        plt.xlabel("intensity")

    plt.tight_layout()
    #plt.show()
    return fig

def intensity_hist_by_pixel(data, sample_data, D, k):
    fig = plt.figure(figsize=(15,15), dpi=100)
    for i in range(D**2):
        plt.subplot(D,D,i+1)

        x, y = divmod(i, D)
        plt.hist(data[torch.tensor((data.info["predictions"] == k).values)][:,x,y], bins=50, alpha=0.3, density=True, range=(50,550))
        plt.hist(sample_data[torch.tensor((data.info["predictions"] == k).values)][:,x,y], bins=50, alpha=0.3, density=True, range=(50,550))
        plt.gca().axes.xaxis.set_ticklabels([])
        plt.gca().axes.yaxis.set_ticklabels([])

    plt.tight_layout()
    return fig